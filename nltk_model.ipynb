{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import text blobs\n",
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and inspect the train data\n",
    "df = pd.read_csv('csvs/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Polarity Function\n",
    "# Define function that accepts text and shows the polarity\n",
    "def detect_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df['comment_text']\n",
    "y = df['toxic']\n",
    "y2 = df['severe_toxic']\n",
    "y3 = df['obscene']\n",
    "y4 = df['threat']\n",
    "y5 = df['insult']\n",
    "y6 = df['identity_hate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, random_state=42)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X, y3, random_state=42)\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X, y4, random_state=42)\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X, y5, random_state=42)\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(X, y6, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 196246)\n",
      "Logistic Regression Score: 0.9531998094903867\n"
     ]
    }
   ],
   "source": [
    "#Tokenization with tfidf\n",
    "vect = TfidfVectorizer(lowercase=False, stop_words='english', decode_error='replace', strip_accents='unicode')\n",
    "\n",
    "# Create document-term matrices\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "print(X_train_dtm.shape)\n",
    "\n",
    "# Use Logistic Regression to predict if it's toxic\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train_dtm, y_train)\n",
    "\n",
    "y_pred = log.predict(X_test_dtm)\n",
    "\n",
    "print(f\"Logistic Regression Score: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 196246)\n",
      "Logistic Regression Score: 0.9903241170130098\n"
     ]
    }
   ],
   "source": [
    "#Tokenization with tfidf\n",
    "vect2 = TfidfVectorizer(lowercase=False, stop_words='english', decode_error='replace', strip_accents='unicode' )\n",
    "\n",
    "# Create document-term matrices\n",
    "X2_train_dtm = vect2.fit_transform(X2_train)\n",
    "X2_test_dtm = vect2.transform(X2_test)\n",
    "\n",
    "print(X2_train_dtm.shape)\n",
    "\n",
    "# Use Logistic Regression to predict if it's severe toxic\n",
    "log2 = LogisticRegression()\n",
    "log2.fit(X2_train_dtm, y2_train)\n",
    "\n",
    "y2_pred = log2.predict(X2_test_dtm)\n",
    "\n",
    "print(f\"Logistic Regression Score: {accuracy_score(y2_test, y2_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 196246)\n",
      "Logistic Regression Score: 0.9736294588022961\n"
     ]
    }
   ],
   "source": [
    "#Tokenization with tfidf\n",
    "vect3 = TfidfVectorizer(lowercase=False, stop_words='english', decode_error='replace', strip_accents='unicode')\n",
    "\n",
    "# Create document-term matrices\n",
    "X3_train_dtm = vect3.fit_transform(X3_train)\n",
    "X3_test_dtm = vect3.transform(X3_test)\n",
    "\n",
    "print(X3_train_dtm.shape)\n",
    "\n",
    "# Use Logistic Regression to predict if it's obscene\n",
    "log3 = LogisticRegression()\n",
    "log3.fit(X3_train_dtm, y3_train)\n",
    "\n",
    "y3_pred = log3.predict(X3_test_dtm)\n",
    "\n",
    "print(f\"Logistic Regression Score: {accuracy_score(y3_test, y3_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 196246)\n",
      "Logistic Regression Score: 0.997443160454215\n"
     ]
    }
   ],
   "source": [
    "#Tokenization with tfidf\n",
    "vect4 = TfidfVectorizer(lowercase=False, stop_words='english', decode_error='replace', strip_accents='unicode')\n",
    "\n",
    "# Create document-term matrices\n",
    "X4_train_dtm = vect4.fit_transform(X4_train)\n",
    "X4_test_dtm = vect4.transform(X4_test)\n",
    "\n",
    "print(X4_train_dtm.shape)\n",
    "\n",
    "# Use Logistic Regression to predict if it's threat\n",
    "log4 = LogisticRegression()\n",
    "log4.fit(X4_train_dtm, y4_train)\n",
    "\n",
    "y4_pred = log4.predict(X4_test_dtm)\n",
    "\n",
    "print(f\"Logistic Regression Score: {accuracy_score(y4_test, y4_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 196246)\n",
      "Logistic Regression Score: 0.9681147068407991\n"
     ]
    }
   ],
   "source": [
    "#Tokenization with tfidf\n",
    "vect5 = TfidfVectorizer(lowercase=False, stop_words='english', decode_error='replace', strip_accents='unicode')\n",
    "\n",
    "# Create document-term matrices\n",
    "X5_train_dtm = vect5.fit_transform(X5_train)\n",
    "X5_test_dtm = vect5.transform(X5_test)\n",
    "\n",
    "print(X5_train_dtm.shape)\n",
    "\n",
    "# Use Logistic Regression to predict if it's insult\n",
    "log5 = LogisticRegression()\n",
    "log5.fit(X5_train_dtm, y5_train)\n",
    "\n",
    "y5_pred = log5.predict(X5_test_dtm)\n",
    "\n",
    "print(f\"Logistic Regression Score: {accuracy_score(y5_test, y5_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 196246)\n",
      "Logistic Regression Score: 0.9914521344596796\n"
     ]
    }
   ],
   "source": [
    "#Tokenization with tfidf\n",
    "vect6 = TfidfVectorizer(lowercase=False, stop_words='english', decode_error='replace', strip_accents='unicode')\n",
    "\n",
    "# Create document-term matrices\n",
    "X6_train_dtm = vect6.fit_transform(X6_train)\n",
    "X6_test_dtm = vect6.transform(X6_test)\n",
    "\n",
    "print(X6_train_dtm.shape)\n",
    "\n",
    "# Use Logistic Regression to predict if it's identity hate\n",
    "log6 = LogisticRegression()\n",
    "log6.fit(X6_train_dtm, y6_train)\n",
    "\n",
    "y6_pred = log6.predict(X6_test_dtm)\n",
    "\n",
    "print(f\"Logistic Regression Score: {accuracy_score(y6_test, y6_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vect, open(\"pickle/vect.sav\", 'wb'))\n",
    "pickle.dump(vect2, open(\"pickle/vect2.sav\", 'wb'))\n",
    "pickle.dump(vect3, open(\"pickle/vect3.sav\", 'wb'))\n",
    "pickle.dump(vect4, open(\"pickle/vect4.sav\", 'wb'))\n",
    "pickle.dump(vect5, open(\"pickle/vect5.sav\", 'wb'))\n",
    "pickle.dump(vect6, open(\"pickle/vect6.sav\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(log, open(\"pickle/toxic.sav\", 'wb'))\n",
    "pickle.dump(log2, open(\"pickle/severetoxic.sav\", 'wb'))\n",
    "pickle.dump(log3, open(\"pickle/obscene.sav\", 'wb'))\n",
    "pickle.dump(log4, open(\"pickle/threat.sav\", 'wb'))\n",
    "pickle.dump(log5, open(\"pickle/insult.sav\", 'wb'))\n",
    "pickle.dump(log6, open(\"pickle/identityhate.sav\", 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
